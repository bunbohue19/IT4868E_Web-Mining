{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "709da377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import datasets\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "from torch import nn \n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d850604",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfoNCELoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, embeddings_a, embeddings_b):\n",
    "        embeddings_a = F.normalize(embeddings_a, dim=1)\n",
    "        embeddings_b = F.normalize(embeddings_b, dim=1)\n",
    "\n",
    "        similarity_matrix = (\n",
    "            embeddings_a @ embeddings_b.T\n",
    "        ) / self.temperature \n",
    "\n",
    "        labels = torch.arange(\n",
    "            embeddings_a.size(0),\n",
    "            device=embeddings_a.device\n",
    "        )\n",
    "\n",
    "        return self.criterion(similarity_matrix, labels)\n",
    "    \n",
    "\n",
    "def batch_to_device(batch, device):\n",
    "    return {key: value.to(device) for key, value in batch.items()}\n",
    "def mean_pooling(last_hidden_state, attention_mask):\n",
    "    mask = attention_mask.unsqueeze(-1).float()\n",
    "    return (last_hidden_state * mask).sum(1) / mask.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c17f2cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0fae0f7aba472286989f1b02bbc5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Alibaba-NLP/new-impl:\n",
      "- configuration.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0bed760dc74f818ac54f24e258353b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Alibaba-NLP/new-impl:\n",
      "- modeling.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700696939aef4385bf09d72667958d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/611M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load model and dataset\n",
    "model_name = \"Alibaba-NLP/gte-multilingual-base\"\n",
    "dataset = datasets.load_dataset(\"jaeyong2/Ja-emb-PreView\")\n",
    "train_dataloader = DataLoader(dataset['train'], batch_size=8, shuffle=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name, trust_remote_code=True)\n",
    "infoloss = InfoNCELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Convert model to bfloat16 if supported\n",
    "if torch.cuda.is_available() and torch.cuda.is_bf16_supported():\n",
    "    model = model.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd957ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = False\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "MAX_LEN_CONTEXT = 256\n",
    "MAX_LEN_TITLE = 128\n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ff1dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   3%|▎         | 535/17467 [06:33<3:27:18,  1.36it/s]"
     ]
    }
   ],
   "source": [
    "from torch.amp import autocast\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "criterion = InfoNCELoss(temperature=0.07)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        context_enc = tokenizer(\n",
    "            batch[\"context\"],\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=MAX_LEN_CONTEXT,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        title_enc = tokenizer(\n",
    "            batch[\"Title\"],\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=MAX_LEN_TITLE,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        context_enc = batch_to_device(context_enc, device)\n",
    "        title_enc = batch_to_device(title_enc, device)\n",
    "        with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "            context_emb = model(**context_enc).last_hidden_state[:, 0, :]\n",
    "            title_emb   = model(**title_enc).last_hidden_state[:, 0, :]\n",
    "\n",
    "            loss = criterion(context_emb, title_emb)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1} | Avg Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bc088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040da8da",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"HUGGINGFACE_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0ea01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"chanchinn/jp_infoNCE_multilingual_embedding_model\"\n",
    "\n",
    "print(f\"Uploading to {model_name}...\")\n",
    "\n",
    "try:\n",
    "    model.push_to_hub(\n",
    "        model_name,\n",
    "        commit_message=\"Fine-tuned with InfoNCE loss\"\n",
    "    )\n",
    "    tokenizer.push_to_hub(\n",
    "        model_name,\n",
    "        commit_message=\"Fine-tuned with InfoNCE loss\"\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"✗ Upload failed!\")\n",
    "    print(f\"Error: {type(e).__name__}: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"✓ Model uploaded successfully!\")\n",
    "    print(f\"View at: https://huggingface.co/{model_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
